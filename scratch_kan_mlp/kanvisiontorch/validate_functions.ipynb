{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getsplines import get_bsplines_torch, get_bsplines\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26894142 -0.2674181  -0.26576883 -0.2639911  -0.26208237 -0.26004013\n",
      " -0.25786187 -0.2555451  -0.25308735 -0.25048616 -0.24773907 -0.24484368\n",
      " -0.2417976  -0.23859844 -0.23524387 -0.23173157 -0.22805927 -0.22422473\n",
      " -0.22022573 -0.21606011 -0.21172574 -0.20722054 -0.20254247 -0.19768953\n",
      " -0.1926598  -0.18745137 -0.18206243 -0.17649118 -0.1707359  -0.16479495\n",
      " -0.15866671 -0.15234965 -0.1458423  -0.13914326 -0.1322512  -0.12516484\n",
      " -0.117883   -0.11040456 -0.10272846 -0.09485374 -0.08677951 -0.07850495\n",
      " -0.07002932 -0.06135196 -0.05247231 -0.04338985 -0.03410418 -0.02461497\n",
      " -0.01492196 -0.005025    0.00507601  0.01538107  0.02589008  0.03660289\n",
      "  0.04751924  0.0586388   0.06996117  0.08148583  0.09321222  0.10513968\n",
      "  0.11726747  0.12959477  0.1421207   0.15484427  0.16776445  0.18088011\n",
      "  0.19419007  0.20769305  0.22138772  0.23527269  0.24934647  0.26360753\n",
      "  0.27805428  0.29268505  0.30749812  0.32249172  0.337664    0.35301309\n",
      "  0.36853704  0.38423385  0.40010151  0.41613791  0.43234093  0.4487084\n",
      "  0.46523813  0.48192785  0.4987753   0.51577816  0.53293409  0.55024073\n",
      "  0.56769566  0.58529649  0.60304076  0.62092601  0.63894977  0.65710955\n",
      "  0.67540284  0.69382713  0.71237988  0.73105858]\n",
      "[0.07232949 0.0785007  0.08479736 0.0912192  0.09776581 0.10443671\n",
      " 0.11123131 0.11814892 0.12518874 0.13234986 0.13963129 0.14703189\n",
      " 0.15455045 0.16218564 0.169936   0.1778     0.18577595 0.19386211\n",
      " 0.20205657 0.21035737 0.21876239 0.22726943 0.23587619 0.24458024\n",
      " 0.25337907 0.26227005 0.27125047 0.28031751 0.28946825 0.29869968\n",
      " 0.30800871 0.31739215 0.32684672 0.33636907 0.34595578 0.35560333\n",
      " 0.36530815 0.37506659 0.38487494 0.39472943 0.40462625 0.4145615\n",
      " 0.42453129 0.43453163 0.44455854 0.45460799 0.4646759  0.47475821\n",
      " 0.4848508  0.49494958 0.50505042 0.5151492  0.52524179 0.5353241\n",
      " 0.54539201 0.55544146 0.56546837 0.57546871 0.5854385  0.59537375\n",
      " 0.60527057 0.61512506 0.62493341 0.63469185 0.64439667 0.65404422\n",
      " 0.66363093 0.67315328 0.68260785 0.69199129 0.70130032 0.71053175\n",
      " 0.71968249 0.72874953 0.73772995 0.74662093 0.75541976 0.76412381\n",
      " 0.77273057 0.78123761 0.78964263 0.79794343 0.80613789 0.81422405\n",
      " 0.8222     0.830064   0.83781436 0.84544955 0.85296811 0.86036871\n",
      " 0.86765014 0.87481126 0.88185108 0.88876869 0.89556329 0.90223419\n",
      " 0.9087808  0.91520264 0.9214993  0.92767051]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "x_bounds = [-1, 1]\n",
    "n_basis = 10\n",
    "edge_fun, edge_fun_der = get_bsplines(x_bounds, n_basis, k=3)\n",
    "x = np.linspace(-1, 1, 100)\n",
    "\n",
    "# Test the functions\n",
    "print(edge_fun[0](x))\n",
    "print(edge_fun_der[0](x))\n",
    "print(edge_fun[1](x))\n",
    "print(edge_fun_der[1](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2689, -0.2674, -0.2658, -0.2640, -0.2621, -0.2600, -0.2579, -0.2555,\n",
      "        -0.2531, -0.2505, -0.2477, -0.2448, -0.2418, -0.2386, -0.2352, -0.2317,\n",
      "        -0.2281, -0.2242, -0.2202, -0.2161, -0.2117, -0.2072, -0.2025, -0.1977,\n",
      "        -0.1927, -0.1875, -0.1821, -0.1765, -0.1707, -0.1648, -0.1587, -0.1523,\n",
      "        -0.1458, -0.1391, -0.1323, -0.1252, -0.1179, -0.1104, -0.1027, -0.0949,\n",
      "        -0.0868, -0.0785, -0.0700, -0.0614, -0.0525, -0.0434, -0.0341, -0.0246,\n",
      "        -0.0149, -0.0050,  0.0051,  0.0154,  0.0259,  0.0366,  0.0475,  0.0586,\n",
      "         0.0700,  0.0815,  0.0932,  0.1051,  0.1173,  0.1296,  0.1421,  0.1548,\n",
      "         0.1678,  0.1809,  0.1942,  0.2077,  0.2214,  0.2353,  0.2493,  0.2636,\n",
      "         0.2781,  0.2927,  0.3075,  0.3225,  0.3377,  0.3530,  0.3685,  0.3842,\n",
      "         0.4001,  0.4161,  0.4323,  0.4487,  0.4652,  0.4819,  0.4988,  0.5158,\n",
      "         0.5329,  0.5502,  0.5677,  0.5853,  0.6030,  0.6209,  0.6389,  0.6571,\n",
      "         0.6754,  0.6938,  0.7124,  0.7311], device='cuda:0')\n",
      "tensor([0.0723, 0.0785, 0.0848, 0.0912, 0.0978, 0.1044, 0.1112, 0.1181, 0.1252,\n",
      "        0.1323, 0.1396, 0.1470, 0.1546, 0.1622, 0.1699, 0.1778, 0.1858, 0.1939,\n",
      "        0.2021, 0.2104, 0.2188, 0.2273, 0.2359, 0.2446, 0.2534, 0.2623, 0.2713,\n",
      "        0.2803, 0.2895, 0.2987, 0.3080, 0.3174, 0.3268, 0.3364, 0.3460, 0.3556,\n",
      "        0.3653, 0.3751, 0.3849, 0.3947, 0.4046, 0.4146, 0.4245, 0.4345, 0.4446,\n",
      "        0.4546, 0.4647, 0.4748, 0.4849, 0.4949, 0.5051, 0.5151, 0.5252, 0.5353,\n",
      "        0.5454, 0.5554, 0.5655, 0.5755, 0.5854, 0.5954, 0.6053, 0.6151, 0.6249,\n",
      "        0.6347, 0.6444, 0.6540, 0.6636, 0.6732, 0.6826, 0.6920, 0.7013, 0.7105,\n",
      "        0.7197, 0.7287, 0.7377, 0.7466, 0.7554, 0.7641, 0.7727, 0.7812, 0.7896,\n",
      "        0.7979, 0.8061, 0.8142, 0.8222, 0.8301, 0.8378, 0.8454, 0.8530, 0.8604,\n",
      "        0.8677, 0.8748, 0.8819, 0.8888, 0.8956, 0.9022, 0.9088, 0.9152, 0.9215,\n",
      "        0.9277], device='cuda:0')\n",
      "tensor([1.6667e-01, 1.3375e-01, 1.0549e-01, 8.1513e-02, 6.1478e-02, 4.5028e-02,\n",
      "        3.1810e-02, 2.1471e-02, 1.3657e-02, 8.0140e-03, 4.1893e-03, 1.8290e-03,\n",
      "        5.7972e-04, 8.7945e-05, 1.7177e-07,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan], device='cuda:0')\n",
      "tensor([-1.7500e+00, -1.5113e+00, -1.2900e+00, -1.0863e+00, -9.0009e-01,\n",
      "        -7.3135e-01, -5.8012e-01, -4.4638e-01, -3.3014e-01, -2.3140e-01,\n",
      "        -1.5016e-01, -8.6420e-02, -4.0174e-02, -1.1427e-02, -1.7855e-04,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x_bounds = [-1, 1]\n",
    "n_basis = 10\n",
    "edge_fun, edge_fun_der = get_bsplines_torch(x_bounds, n_basis, k=3)\n",
    "x = torch.linspace(-1, 1, steps=100, device='cuda')\n",
    "\n",
    "# Test the functions\n",
    "print(edge_fun[0](x))\n",
    "print(edge_fun_der[0](x))\n",
    "print(edge_fun[1](x))\n",
    "print(edge_fun_der[1](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiLU: tensor([ 0.3112, -0.1888,  0.7311, -0.2689], device='cuda:0')\n",
      "Softmax: tensor([0.3087, 0.1136, 0.5089, 0.0689], device='cuda:0')\n",
      "ReLU: tensor([0.5000, 0.0000, 1.0000, 0.0000], device='cuda:0')\n",
      "Tanh: tensor([ 0.4621, -0.4621,  0.7616, -0.7616], device='cuda:0')\n",
      "Sigmoid: tensor([0.6225, 0.3775, 0.7311, 0.2689], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from activations import silu, sigmoid, tanh_act, relu, softmax\n",
    "\n",
    "x = torch.tensor([0.5, -0.5, 1.0, -1.0], device='cuda')\n",
    "print(\"SiLU:\", silu(x))\n",
    "print(\"Softmax:\", softmax(x))\n",
    "print(\"ReLU:\", relu(x))\n",
    "print(\"Tanh:\", tanh_act(x))\n",
    "print(\"Sigmoid:\", sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3468, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir-machine/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kanneuron.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.input_values = torch.tensor(input_values, device=self.device, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from kanneuron import KANNeuron\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_values = torch.Tensor([0.5198,  0.7921,  2.0196,  1.4262, -0.3211]).to(device)\n",
    "kan_neuron = KANNeuron(n_in=5, n_weights_per_edge=5, x_bounds=[-1, 1], device=device)\n",
    "output = kan_neuron(input_values)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic_number = int.from_bytes(f.read(4), byteorder='big')\n",
    "        num_dims = magic_number & 0xFF\n",
    "        shape = tuple(int.from_bytes(f.read(4), byteorder='big') for _ in range(num_dims))\n",
    "        \n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return data.reshape(shape)\n",
    "\n",
    "# Load training images\n",
    "train_images_path = '/home/emir-machine/dev/datasets/train-images-idx3-ubyte'\n",
    "train_labels = '/home/emir-machine/dev/datasets/train-labels-idx1-ubyte'\n",
    "train_images = read_idx(train_images_path)\n",
    "train_labels = read_idx(train_labels)\n",
    "print(f'Training images shape: {train_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_one_hot = onehot_encoder.fit_transform(train_labels.reshape(-1, 1))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_images = torch.tensor(train_images).unsqueeze(1)  # Add channel dimension\n",
    "train_labels_one_hot = torch.tensor(train_labels_one_hot, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 1\n",
    "train_dataset = TensorDataset(train_images, train_labels_one_hot)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28]) torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3975/3640999758.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_images = torch.tensor(train_images)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "train_images = torch.tensor(train_images)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_dataset_subset = torch.utils.data.random_split(train_dataset, [10000, len(train_dataset)-10000])[0]\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset_subset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emir-machine/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kanneuron.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.input_values = torch.tensor(input_values, device=self.device, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 0/10000: Loss = 2.8047075271606445\n",
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 1/10000: Loss = 1.9499844312667847\n",
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 2/10000: Loss = 2.123718738555908\n",
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 3/10000: Loss = 3.4285948276519775\n",
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 4/10000: Loss = 2.2822940349578857\n",
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 5/10000: Loss = 3.615345001220703\n",
      "torch.Size([1, 1, 24, 24])\n",
      "Batch 6/10000: Loss = 1.8493117094039917\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m batch_images, batch_labels \u001b[38;5;241m=\u001b[39m batch_images\u001b[38;5;241m.\u001b[39mto(device), batch_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(batch_images.shape, batch_labels.shape)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fun(preds, batch_labels)\n\u001b[1;32m     21\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/convkantorch.py:31\u001b[0m, in \u001b[0;36mKANClassification.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_layers:\n\u001b[0;32m---> 31\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# x = x.view(x.size(0), -1)  # Flatten the tensor\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/convkantorch.py:102\u001b[0m, in \u001b[0;36mConvKANLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, in_width \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride):\n\u001b[1;32m    101\u001b[0m                 region \u001b[38;5;241m=\u001b[39m x[b, :, i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size, j:j \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size]\n\u001b[0;32m--> 102\u001b[0m                 out[b, o, i \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkan_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kannetworktorch.py:62\u001b[0m, in \u001b[0;36mKANNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m x_in \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m li \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m---> 62\u001b[0m     x_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mli\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_in\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kannetworktorch.py:20\u001b[0m, in \u001b[0;36mLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxin \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxout \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([neuron(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxin) \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxout\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kannetworktorch.py:20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxin \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxout \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxin\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxout\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kanneuron.py:40\u001b[0m, in \u001b[0;36mNeuron.__call__\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_derivative_output_wrt_edge()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_derivative_output_wrt_bias()\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_derivative_edge_wrt_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_derivative_edge_wrt_input()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_output_wrt_edge\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_inputs,)\n",
      "File \u001b[0;32m~/dev/kan_basics/scratch_kan_mlp/kanvisiontorch/kanneuron.py:109\u001b[0m, in \u001b[0;36mKANNeuron.compute_derivative_edge_wrt_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_derivative_edge_wrt_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mderivative_edge_wrt_weights\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_x_mat\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from convkantorch import KANClassification\n",
    "from loss import CrossEntropyLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = KANClassification(input_channel=1, height=28, width=28, device=device)\n",
    "loss_fun = CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "\n",
    "epochs = 10  # Number of epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch_images, batch_labels = batch\n",
    "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "        # print(batch_images.shape, batch_labels.shape)\n",
    "        preds = model.forward(batch_images)\n",
    "        \n",
    "        loss = loss_fun(preds, batch_labels)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        # Backward pass\n",
    "        model.backward(loss_fun.dloss_dy.squeeze())\n",
    "        \n",
    "        model.zero_grad(which=['xin'])\n",
    "        print(f\"Batch {i}/{len(train_loader)}: Loss = {loss / batch_size}\")\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "    model.update()\n",
    "    model.zero_grad(which=['weights', 'bias'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(60000 * 4) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.944444444444445"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.5 * 10000) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
